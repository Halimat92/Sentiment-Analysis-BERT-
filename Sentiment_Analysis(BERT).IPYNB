{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BpeD457YnGf",
    "outputId": "70e1229b-f613-439a-c50b-b32a18badaba"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "BUAGVXaRaYYG",
    "outputId": "37308a74-a922-4950-88d5-35ab2599bfcd"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QetSA9QpJMCV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJMfVMZ4nlCU",
    "outputId": "28d56fd7-434c-4188-a8f5-96f185e4c42c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"amazon_reviews_us_Electronics_v1_.csv\")\n",
    "\n",
    "# Drop rows with missing values in relevant columns\n",
    "df = df[['review_body', 'star_rating']].dropna()\n",
    "\n",
    "# Convert star_rating to integer\n",
    "df['star_rating'] = df['star_rating'].astype(int)\n",
    "\n",
    "# Map star_rating to sentiment classes\n",
    "def map_rating(r):\n",
    "    if r <= 2:\n",
    "        return 0  # negative\n",
    "    elif r == 3:\n",
    "        return 1  # neutral\n",
    "    else:\n",
    "        return 2  # positive\n",
    "\n",
    "df['sentiment'] = df['star_rating'].apply(map_rating)\n",
    "\n",
    "# Rename 'review_body' to 'reviews'\n",
    "df = df.rename(columns={'review_body': 'reviews'})\n",
    "\n",
    "# Keep only the renamed columns\n",
    "df = df[['reviews', 'sentiment']]\n",
    "\n",
    "# Optionally save to CSV\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "# Display a sample\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jjm74EscKbcO"
   },
   "source": [
    "#### Save the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zf6foyLPK0fk"
   },
   "outputs": [],
   "source": [
    "output_dir = \"/content/drive/MyDrive/sentiment_bert_data\"\n",
    "!mkdir -p \"{output_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hkMpsb-QdPD",
    "outputId": "3898b11d-e08b-44e2-9abb-175a578b0a2c"
   },
   "outputs": [],
   "source": [
    "# Load your reduced dataset\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/cleaned_data.csv\")\n",
    "\n",
    "# Check class distribution\n",
    "label_counts = df['labels'].value_counts().sort_index()\n",
    "\n",
    "# Print counts\n",
    "print(\"Class distribution:\\n\", label_counts)\n",
    "\n",
    "# # visualize\n",
    "# label_names = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "# label_counts.rename(index=label_names).plot(kind='bar', color='skyblue', title='Class Distribution')\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8eATqWFHJkvQ",
    "outputId": "8ab4d323-8d78-4530-c114-547c5d65b5ea"
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gfXO0LlJsLX"
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"labels\"], random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"labels\"], random_state=42)\n",
    "\n",
    "# Convert to HF datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets":[
     ]
    },
    "id": "I3tNrKUs5TJb",
    "outputId": "98e57135-7340-4582-8742-cfb1ea14b0b5"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "valid_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Save everything\n",
    "save_dir = \"/content/drive/MyDrive/sentiment_bert_balanced\"\n",
    "train_dataset.save_to_disk(f\"{save_dir}/train\")\n",
    "valid_dataset.save_to_disk(f\"{save_dir}/valid\")\n",
    "test_dataset.save_to_disk(f\"{save_dir}/test\")\n",
    "tokenizer.save_pretrained(f\"{save_dir}/tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-f6Fv8GMQOS"
   },
   "source": [
    "### We will be training our model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "LSL9zRZEMm4k",
    "outputId": "c0bf0cd7-6672-4dd9-99c5-5d8bdf040b0e"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "referenced_widgets": [
     ]
    },
    "id": "yZHVtUgdT-Ga",
    "outputId": "6c502394-1d24-4cf7-d0f6-fed893faba2a"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "#  Load pre-tokenized datasets and tokenizer from Google Drive\n",
    "save_dir = \"/content/drive/MyDrive/sentiment_bert_balanced\"\n",
    "train_dataset = load_from_disk(f\"{save_dir}/train\")\n",
    "valid_dataset = load_from_disk(f\"{save_dir}/valid\")\n",
    "test_dataset = load_from_disk(f\"{save_dir}/test\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{save_dir}/tokenizer\")\n",
    "\n",
    "#  Set PyTorch format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_dataset.set_format(\"torch\", columns=columns)\n",
    "valid_dataset.set_format(\"torch\", columns=columns)\n",
    "test_dataset.set_format(\"torch\", columns=columns)\n",
    "\n",
    "#  Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "#  Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "#  Metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "#  Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{save_dir}/model\",                #  Save to Drive\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,                             #  Reduced to avoid overfitting\n",
    "    learning_rate=1e-5,                             #  Lower LR\n",
    "    weight_decay=0.05,                              #  Stronger regularization\n",
    "    warmup_steps=500,\n",
    "    logging_steps=20,\n",
    "    run_name=\"sentiment_final\",\n",
    "    report_to=\"none\"                                # Skip wandb/logging if not needed\n",
    ")\n",
    "\n",
    "#  Trainer with Early Stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "7pHg4IuzVGDB",
    "outputId": "a77ae4e6-575b-4298-a6c7-ca34786c0006"
   },
   "outputs": [],
   "source": [
    "#  Start training\n",
    "trainer.train()\n",
    "\n",
    "#  Save best model & tokenizer to Drive\n",
    "trainer.save_model(f\"{save_dir}/model\")\n",
    "tokenizer.save_pretrained(f\"{save_dir}/model\")\n",
    "print(\"‚úÖ Training complete. Best model and tokenizer saved to Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDKEKo9FyN5L"
   },
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ev5RBG5yWMI",
    "outputId": "1426c4f1-af4f-4ae8-d554-da920bf800f1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "BS_RKPvB0NLH",
    "outputId": "c0bf0cd7-6672-4dd9-99c5-5d8bdf040b0e"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNthX4Tdz6Rb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import accuracy_score, f1_score,confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "# from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eH9Skuncydll"
   },
   "outputs": [],
   "source": [
    "# Set your saved model directory\n",
    "model_dir = \"/content/drive/MyDrive/sentiment_bert_balanced/model\"\n",
    "\n",
    "# Load trained model & tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "###### Load Test dataset\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/sentiment_bert_balanced\"\n",
    "test_dataset = load_from_disk(f\"{save_dir}/test\")\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbF6mz_Pq4oj",
    "outputId": "53e00e38-c34e-4f59-a2fc-651b3eb22c50"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def evaluate(dataset, name):\n",
    "    loader = DataLoader(dataset, batch_size=32, collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"üìä {name} Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Run evaluation\n",
    "train_dataset = load_from_disk(f\"{save_dir}/train\")\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "valid_dataset = load_from_disk(f\"{save_dir}/valid\")\n",
    "valid_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_labels, train_preds = evaluate(train_dataset, \"Train\")\n",
    "valid_labels, valid_preds = evaluate(valid_dataset, \"Validation\")\n",
    "test_labels, test_preds = evaluate(test_dataset, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "LJkCubKkq8Vl",
    "outputId": "d9136e3b-a741-493b-f8ab-7b9b78323c46"
   },
   "outputs": [],
   "source": [
    "def plot_cm(true, pred, name):\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Neg\", \"Neutral\", \"Pos\"], yticklabels=[\"Neg\", \"Neutral\", \"Pos\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_cm(test_labels, test_preds, \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YASu_E7zXFw"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aslk0u7Dq8fS",
    "outputId": "07381568-187d-4fad-cc90-0c906b7d987b"
   },
   "outputs": [],
   "source": [
    "def predict_sample(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return [\"Negative\", \"Neutral\", \"Positive\"][pred]\n",
    "\n",
    "# Try a few custom texts\n",
    "samples = [\n",
    "    \"This phone is amazing! Totally worth the price.\",\n",
    "    \"Battery life is okay, not the best.\",\n",
    "    \"Terrible product. I want a refund.\",\n",
    "    \"Arrived early, but the phone is not good at all\",\n",
    "    \"Arrived late, but the phone is so good\",\n",
    "]\n",
    "\n",
    "for text in samples:\n",
    "    print(f\"üìù \\\"{text}\\\" ‚Üí Prediction: {predict_sample(text)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diqhqYifznqB"
   },
   "source": [
    "## Gradio Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "CKPFQZ0Gi5KT",
    "outputId": "518e2ea0-c3c3-4468-c9f5-e24f591bf0f8"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/sentiment_bert_balanced/model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "colors = {\"Negative\": \"red\", \"Neutral\": \"gray\", \"Positive\": \"green\"}\n",
    "FEEDBACK_FILE = \"user_feedback.csv\"\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).squeeze()\n",
    "        predicted_class = torch.argmax(probs).item()\n",
    "\n",
    "    label = label_map[predicted_class]\n",
    "    confidence = probs[predicted_class].item()\n",
    "    warning = \"<br><span style='color:orange'>‚ö†Ô∏è Low confidence. Try rephrasing the review.</span>\" if confidence < 0.5 else \"\"\n",
    "\n",
    "    result_html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {colors[label]}; padding: 10px; border-radius: 10px;\">\n",
    "        <h3 style='margin-bottom: 5px;'>Prediction: <span style='color:{colors[label]}'>{label}</span></h3>\n",
    "        <p>Confidence: {confidence:.2%}</p>\n",
    "        {warning}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return result_html, label, confidence\n",
    "\n",
    "def save_feedback(label, confidence, correct):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    file_exists = os.path.isfile(FEEDBACK_FILE)\n",
    "    with open(FEEDBACK_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"timestamp\", \"predicted_label\", \"confidence\", \"correct_prediction\"])\n",
    "        writer.writerow([timestamp, label, f\"{confidence:.2%}\", correct])\n",
    "    return \"‚úÖ Thanks for your feedback!\"\n",
    "\n",
    "with gr.Blocks(title=\"Amazon Review Sentiment App\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"<div style='text-align: center; font-size: 24px;'> <b> üí¨üìä Review Analyzer</b></div>\"\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"Enter a review below to check if it's **Positive üòä**, **Neutral üòê**, or **Negative üòû**.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        review_input = gr.Textbox(lines=10, placeholder=\"Type or paste a review here...\", label=\"Your Review\")\n",
    "        output_box = gr.HTML(label=\"Prediction Result\")\n",
    "\n",
    "    predict_btn = gr.Button(\"üîç Predict Sentiment\")\n",
    "    hidden_label = gr.Textbox(visible=False)\n",
    "    hidden_conf = gr.Number(visible=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        yes_btn = gr.Button(\"üëç Yes\")\n",
    "        no_btn = gr.Button(\"üëé No\")\n",
    "\n",
    "    feedback_output = gr.Textbox(label=\"Feedback Status\", interactive=False)\n",
    "\n",
    "    predict_btn.click(fn=predict_sentiment, inputs=[review_input], outputs=[output_box, hidden_label, hidden_conf])\n",
    "    yes_btn.click(fn=save_feedback, inputs=[hidden_label, hidden_conf, gr.Textbox(value=\"yes\", visible=False)], outputs=feedback_output)\n",
    "    no_btn.click(fn=save_feedback, inputs=[hidden_label, hidden_conf, gr.Textbox(value=\"no\", visible=False)], outputs=feedback_output)\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            \"This phone exceeded all my expectations.\",\n",
    "            \"Battery life is just okay, not great.\",\n",
    "            \"Worst product I've ever purchased.\",\n",
    "            \"Highly recommended!\",\n",
    "            \"Meh. It's just fine, nothing special.\"\n",
    "        ],\n",
    "        inputs=review_input\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
